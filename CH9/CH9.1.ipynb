{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7cdc515-714b-4cd9-9375-38e1163d6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a596571-4610-4ad8-8771-066571f3473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutFromScratch(nn.Module):\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mask = (torch.rand_like(x) > self.p).float()\n",
    "            return x * mask / (1 - self.p)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class BatchNorm1dFromScratch(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "        self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "        \n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            batch_mean = x.mean(dim=0)\n",
    "            batch_var = x.var(dim=0, unbiased=False)\n",
    "        \n",
    "            # For running stats, use unbiased variance\n",
    "            batch_var_unbiased = x.var(dim=0, unbiased=True)\n",
    "        \n",
    "            self.running_mean.mul_(1 - self.momentum).add_(self.momentum * batch_mean)\n",
    "            self.running_var.mul_(1 - self.momentum).add_(self.momentum * batch_var_unbiased)\n",
    "        \n",
    "            x_normalized = (x - batch_mean) / torch.sqrt(batch_var + self.eps)\n",
    "        else:\n",
    "            x_normalized = (x - self.running_mean) / torch.sqrt(self.running_var + self.eps)\n",
    "\n",
    "        \n",
    "        return self.gamma * x_normalized + self.beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bf52491-84bd-4cf2-90ce-bfa0e0fa1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dropout():\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    x = torch.randn(4, 10)\n",
    "    custom_dropout = DropoutFromScratch(p=0.5)\n",
    "    pytorch_dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "    custom_dropout.train()\n",
    "    pytorch_dropout.train()\n",
    "    \n",
    "    print(\"Input shape:\", x.shape)\n",
    "    print(\"\\nTraining mode:\")\n",
    "    print(\"Custom dropout output sample:\", custom_dropout(x)[0, :5])\n",
    "    print(\"PyTorch dropout output sample:\", pytorch_dropout(x)[0, :5])\n",
    "    \n",
    "    custom_dropout.eval()\n",
    "    pytorch_dropout.eval()\n",
    "    \n",
    "    print(\"\\nEval mode:\")\n",
    "    print(\"Custom dropout output:\", custom_dropout(x)[0, :5])\n",
    "    print(\"PyTorch dropout output:\", pytorch_dropout(x)[0, :5])\n",
    "    print(\"\\nIn eval mode, both should equal the input:\", x[0, :5])\n",
    "\n",
    "def test_batchnorm():\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    batch_size, num_features = 32, 10\n",
    "    x = torch.randn(batch_size, num_features)\n",
    "    custom_bn = BatchNorm1dFromScratch(num_features)\n",
    "    \n",
    "    pytorch_bn = nn.BatchNorm1d(num_features)\n",
    "    pytorch_bn.weight.data = custom_bn.gamma.data.clone()\n",
    "    pytorch_bn.bias.data = custom_bn.beta.data.clone()\n",
    "    \n",
    "    custom_bn.train()\n",
    "    pytorch_bn.train()\n",
    "    \n",
    "    # üîÅ Simulate multiple training steps to update running stats\n",
    "    for _ in range(100):\n",
    "        custom_bn(x)\n",
    "        pytorch_bn(x)\n",
    "    \n",
    "    print(\"Training mode:\")\n",
    "    custom_out = custom_bn(x)\n",
    "    pytorch_out = pytorch_bn(x)\n",
    "    \n",
    "    print(f\"Custom output mean: {custom_out.mean():.6f}, std: {custom_out.std():.6f}\")\n",
    "    print(f\"PyTorch output mean: {pytorch_out.mean():.6f}, std: {pytorch_out.std():.6f}\")\n",
    "    print(f\"Outputs close? {torch.allclose(custom_out, pytorch_out, atol=1e-5)}\")\n",
    "    \n",
    "    custom_bn.eval()\n",
    "    pytorch_bn.eval()\n",
    "    x_test = torch.randn(16, num_features)\n",
    "    \n",
    "    print(\"\\nEval mode:\")\n",
    "    custom_out = custom_bn(x_test)\n",
    "    pytorch_out = pytorch_bn(x_test)\n",
    "    print(f\"Outputs close? {torch.allclose(custom_out, pytorch_out, atol=1e-5)}\")\n",
    "    print(f\"Max absolute diff: {(custom_out - pytorch_out).abs().max():.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f45d1c3e-f3a2-4a0a-ba66-6b6ce22d8c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 10])\n",
      "\n",
      "Training mode:\n",
      "Custom dropout output sample: tensor([3.8538, 0.0000, 1.8014, -0.0000, 1.3568])\n",
      "PyTorch dropout output sample: tensor([ 3.8538,  0.0000,  1.8014, -4.2110,  1.3568])\n",
      "\n",
      "Eval mode:\n",
      "Custom dropout output: tensor([ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784])\n",
      "PyTorch dropout output: tensor([ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784])\n",
      "\n",
      "In eval mode, both should equal the input: tensor([ 1.9269,  1.4873,  0.9007, -2.1055,  0.6784])\n",
      "Training mode:\n",
      "Custom output mean: 0.000000, std: 1.001561\n",
      "PyTorch output mean: -0.000000, std: 1.001561\n",
      "Outputs close? True\n",
      "\n",
      "Eval mode:\n",
      "Outputs close? True\n",
      "Max absolute diff: 4.768372e-07\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_dropout()\n",
    "    test_batchnorm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
